---
title: "Vogel Lakes Complex Water Quality Data"
author: "Benjamin Meyer"
output:
  html_document: 
    df_print: paged
    fig_width: 10
    fig_height: 6
    fig_caption: yes
    code_folding: hide
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options: 
  chunk_output_type: inline
---

Document last updated `r Sys.time()` by Benjamin Meyer ([ben\@kenaiwatershed.org](mailto:ben@kenaiwatershed.org){.email})

![](images/KWF_logo.png)


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

# clear environment
rm(list=ls())

# load packages
library(tidyverse)
library(googlesheets4)
library(lubridate)
library(readr)
library(readxl)
library(writexl)
library(hms)
library(plotly)
library(DT)
library(xlsx)
library(leaflet)
library(DT)
library(ggpubr)
library(plotrix)

# set plotting themes

## geom_col plots theme
col_theme <- theme(axis.title = element_text(size = 14, face = "bold"),
                   strip.text = element_text(size = 14, face = "bold"),
                   legend.title = element_text(size = 14, face = "bold"),
                   legend.text = element_text(size = 14),
                   axis.text = element_text(size = 14))

## geom_points plots theme
points_theme <- theme(axis.title = element_text(size = 14, face = "bold"),
                   strip.text = element_text(size = 14, face = "bold"),
                   legend.title = element_text(size = 14, face = "bold"),
                   legend.text = element_text(size = 14),
                   axis.text = element_text(size = 14),
                   title = element_text(size = 18))

# function to exclude multiple items per column
'%ni%' <- Negate('%in%')

# clarify select function
select <- dplyr::select
```

<br>

### Summary

This draft document contains preliminary data explorations of 2019-2020 water quality data from the Vogel Lakes complex in the Northern Kenai peninsula.

<br>

Notes:


***


### Data Import

Raw data is stored in a Google Sheet that can be viewed at https://tinyurl.com/kwf-vogel-wqx-data.

Import data from google sheet
```{r}
# Note to self: once project is complete and no more data updates are needed, migrate data source from Google Sheet to csvs in the local project "data" folder

# recognize sheet title
lake_wqx_dat <- read_sheet("https://docs.google.com/spreadsheets/d/1lS9eJ7kX91IlYwSgiEQm-BQqif_7o5E4MzcBmqpwSoI/edit#gid=0", 
                           sheet = "Profile_Measurements") %>%
  # rename columns
  rename(site = `Site Name`,
         sample_date = `Sample Date`,
         sample_depth_m = `Depth (m)`,
         sample_time = `Sample Time`,
         DO_mgl = `DO (mg/L)`,
         turbidity_ntu = `Turbidity (NTU)`,
         temp_c = `Temp (C)`,
         spcond_uscm = `SpCond (uS/cm)`) %>%
  select(-Notes,-QC1,-`Data Entry`,-`QC2`) %>%
  
  # transform column formats
  transform(sample_time = hms::as_hms(sample_time)) %>%
  
  # convert data fromat from wide to long
  pivot_longer(cols = c("pH","DO_mgl","turbidity_ntu","temp_c","spcond_uscm"),
               names_to = "parameter",
               values_to = "val") %>%
  
  # remove missing values
  filter(!is.na(val))


```


<br>

***

### Data Visualization

Vision - plotly objects for each of the sites?


